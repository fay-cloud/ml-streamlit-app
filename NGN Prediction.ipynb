{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b47924b-b477-4451-b43b-ec04d2d8d648",
   "metadata": {},
   "source": [
    "# LSTM Forecasting for NGN/Euro Exchange Rate\n",
    "To achieve your goals of forecasting NGN/EURO prices using LSTM and creating a user interface for future date predictions, I'll outline a comprehensive solution:\n",
    "\n",
    "Solution Approach\n",
    "1. Data Preparation\n",
    "First, we need to properly prepare the time series data for LSTM modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0f24a9a-175f-4220-a563-bd26f1702d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5260038b-f622-48a5-8978-17d83b9f1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= pd.read_csv(\"ngn_eur_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd6999bf-164a-439e-982e-f8a3babfc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df3.copy()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cced9e98-e6b2-4ca7-95bb-398b43eae623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>EUR_NGN_1. open</th>\n",
       "      <th>EUR_NGN_2. high</th>\n",
       "      <th>EUR_NGN_3. low</th>\n",
       "      <th>EUR_NGN_4. close</th>\n",
       "      <th>TRENDS_Euro to Naira</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>222.37</td>\n",
       "      <td>230.14000</td>\n",
       "      <td>222.07001</td>\n",
       "      <td>229.63000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>229.62</td>\n",
       "      <td>229.67000</td>\n",
       "      <td>222.36000</td>\n",
       "      <td>222.48000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-12-03</td>\n",
       "      <td>222.48</td>\n",
       "      <td>222.59000</td>\n",
       "      <td>220.27000</td>\n",
       "      <td>220.37000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-12-04</td>\n",
       "      <td>220.36</td>\n",
       "      <td>224.03999</td>\n",
       "      <td>220.28000</td>\n",
       "      <td>221.64000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>221.63</td>\n",
       "      <td>225.00000</td>\n",
       "      <td>220.28000</td>\n",
       "      <td>220.28999</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  EUR_NGN_1. open  EUR_NGN_2. high  EUR_NGN_3. low  \\\n",
       "16  2014-12-01           222.37        230.14000       222.07001   \n",
       "17  2014-12-02           229.62        229.67000       222.36000   \n",
       "18  2014-12-03           222.48        222.59000       220.27000   \n",
       "19  2014-12-04           220.36        224.03999       220.28000   \n",
       "20  2014-12-05           221.63        225.00000       220.28000   \n",
       "\n",
       "    EUR_NGN_4. close  TRENDS_Euro to Naira  \n",
       "16         229.63000                  15.0  \n",
       "17         222.48000                  15.0  \n",
       "18         220.37000                  15.0  \n",
       "19         221.64000                  15.0  \n",
       "20         220.28999                  15.0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8cd9b46e-b339-4eaf-9595-c13bd2caa90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date   NGN_EURO  Google_Trends\n",
      "16  2014-12-01  229.63000           15.0\n",
      "17  2014-12-02  222.48000           15.0\n",
      "18  2014-12-03  220.37000           15.0\n",
      "19  2014-12-04  221.64000           15.0\n",
      "20  2014-12-05  220.28999           15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kefa\\AppData\\Local\\Temp\\ipykernel_1532\\1288464019.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Rename columns\n",
    "df.rename(columns={\n",
    "    'Unnamed: 0': 'Date',\n",
    "    'EUR_NGN_4. close': 'NGN_EURO',\n",
    "    'TRENDS_Euro to Naira': 'Google_Trends'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef445029-8da3-40d4-93bd-85789af55eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Date', 'Google_Trends', 'NGN_EURO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2357c99e-0ac8-4d44-88d3-ee4ccd3c10f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Google_Trends   NGN_EURO\n",
      "16  2014-12-01           15.0  229.63000\n",
      "17  2014-12-02           15.0  222.48000\n",
      "18  2014-12-03           15.0  220.37000\n",
      "19  2014-12-04           15.0  221.64000\n",
      "20  2014-12-05           15.0  220.28999\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "906ee286-1f33-4c3a-80da-9bf21d7545fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2445 entries, 16 to 2460\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           2445 non-null   object \n",
      " 1   Google_Trends  2445 non-null   float64\n",
      " 2   NGN_EURO       2445 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 76.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "efb69df7-3aef-4200-a58d-2ab2524468e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2445, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6bca32-c08a-4212-94de-b56e1041dd45",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d35c93dc-e3b1-4639-ae5f-ce3a7d420f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google_Trends    0\n",
      "NGN_EURO         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Convert Date to datetime and set as index\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df[['NGN_EURO']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ed96f-f874-4643-974c-361130a7f07c",
   "metadata": {},
   "source": [
    "## Create Time Series Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1b62d21-26a0-4585-b9d0-3c670ee5d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        X.append(data[i:(i+seq_length), 0])\n",
    "        y.append(data[i+seq_length, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define sequence length (e.g., 60 days)\n",
    "seq_length = 60\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "# Split into train/test sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Reshape for LSTM [samples, timesteps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76d74a-c31f-47bc-8619-e1bc960a75bb",
   "metadata": {},
   "source": [
    "## Build and Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbe77abd-1389-476d-aea8-5b0709eebe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kefa\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 1.6252e-04 - val_loss: 0.0045\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 1.5219e-04 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 1.2557e-04 - val_loss: 0.0058\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 1.1892e-04 - val_loss: 0.0073\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 1.3153e-04 - val_loss: 0.0062\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 9.8333e-05 - val_loss: 0.0073\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 9.7030e-05 - val_loss: 0.0105\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 9.0303e-05 - val_loss: 0.0077\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 8.2435e-05 - val_loss: 0.0086\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 8.3295e-05 - val_loss: 0.0071\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 7.8959e-05 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 6.4973e-05 - val_loss: 0.0138\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 7.1010e-05 - val_loss: 0.0091\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 6.0920e-05 - val_loss: 0.0104\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 5.8841e-05 - val_loss: 0.0082\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 5.3954e-05 - val_loss: 0.0091\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 6.6327e-05 - val_loss: 0.0084\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 5.0234e-05 - val_loss: 0.0071\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 5.2372e-05 - val_loss: 0.0096\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 5.1017e-05 - val_loss: 0.0080\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 4.4628e-05 - val_loss: 0.0074\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 4.2319e-05 - val_loss: 0.0064\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 4.8088e-05 - val_loss: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3.9567e-05 - val_loss: 0.0088\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 4.6196e-05 - val_loss: 0.0094\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 4.6088e-05 - val_loss: 0.0058\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 3.5878e-05 - val_loss: 0.0057\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 4.0981e-05 - val_loss: 0.0087\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 4.4013e-05 - val_loss: 0.0073\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 3.9329e-05 - val_loss: 0.0071\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 4.1167e-05 - val_loss: 0.0059\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 4.2192e-05 - val_loss: 0.0036\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.5952e-05 - val_loss: 0.0120\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 4.0114e-05 - val_loss: 0.0060\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 3.9592e-05 - val_loss: 0.0065\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 3.5808e-05 - val_loss: 0.0050\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3.6675e-05 - val_loss: 0.0067\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 4.1668e-05 - val_loss: 0.0051\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 3.9198e-05 - val_loss: 0.0050\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 3.7539e-05 - val_loss: 0.0042\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 4.0137e-05 - val_loss: 0.0046\n",
      "Epoch 43/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 3.7635e-05 - val_loss: 0.0043\n",
      "Epoch 44/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 3.6774e-05 - val_loss: 0.0053\n",
      "Epoch 45/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 4.2267e-05 - val_loss: 0.0033\n",
      "Epoch 46/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.5999e-05 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 3.8729e-05 - val_loss: 0.0030\n",
      "Epoch 48/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 3.4060e-05 - val_loss: 0.0042\n",
      "Epoch 49/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 4.5096e-05 - val_loss: 0.0014\n",
      "Epoch 50/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 2.9234e-05 - val_loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(seq_length, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b348e-085a-4342-ab7d-c8f260fffa24",
   "metadata": {},
   "source": [
    "## Forecasting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0902f584-8c83-4e24-b8e1-55bb445ef2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_future_dates(model, last_sequence, future_dates, scaler):\n",
    "    predictions = []\n",
    "    current_sequence = last_sequence.copy()\n",
    "    \n",
    "    for _ in range(len(future_dates)):\n",
    "        # Predict next value\n",
    "        next_pred = model.predict(current_sequence.reshape(1, seq_length, 1))\n",
    "        \n",
    "        # Store prediction\n",
    "        predictions.append(next_pred[0,0])\n",
    "        \n",
    "        # Update sequence\n",
    "        current_sequence = np.roll(current_sequence, -1)\n",
    "        current_sequence[-1] = next_pred\n",
    "    \n",
    "    # Inverse transform predictions\n",
    "    predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd4bc2-09f8-43f3-9977-efb4f419a3b8",
   "metadata": {},
   "source": [
    "## Here's how to test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6c201aa9-634a-4522-97e8-ecdabcdce3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002461A677CE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Predicted NGN/EURO rate for 2025-04-29: 1726.1964\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming we have our trained model and scaler loaded\n",
    "# model = load_model('ngn_euro_lstm.h5')\n",
    "# scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Test the forecast_future_dates function\n",
    "def test_forecast():\n",
    "    # Get the last sequence from our data (most recent 60 days)\n",
    "    last_sequence = scaled_data[-seq_length:]  # Using the scaled_data from earlier\n",
    "    \n",
    "    # Define our target date (correcting what appears to be a typo - 205 to 2025)\n",
    "    target_date = datetime(2025, 4, 29).date()\n",
    "    today = datetime.today().date()\n",
    "    \n",
    "    # Calculate days ahead (ensure it's a positive number)\n",
    "    days_ahead = (target_date - today).days\n",
    "    if days_ahead <= 0:\n",
    "        print(\"Please select a date in the future\")\n",
    "        return\n",
    "    \n",
    "    # Generate all future dates between tomorrow and target date\n",
    "    future_dates = [today + timedelta(days=i) for i in range(1, days_ahead+1)]\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = forecast_future_dates(model, last_sequence, future_dates, scaler)\n",
    "    \n",
    "    # Get the specific prediction for our target date\n",
    "    target_prediction = predictions[-1][0]\n",
    "    \n",
    "    print(f\"Predicted NGN/EURO rate for {target_date}: {target_prediction:.4f}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Run the test\n",
    "predictions = test_forecast()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d418a1-7cd3-4960-9c31-2ec008ff7d2a",
   "metadata": {},
   "source": [
    "### Saving the Model and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "809afb7e-4296-43bb-8d61-df8effbefbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from keras.models import save_model\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Save the trained LSTM model\n",
    "save_model(model, 'ngn_euro_lstm.h5')  # Saves in HDF5 format\n",
    "\n",
    "# Save the scaler object\n",
    "joblib.dump(scaler, 'ngn_euro_scaler.pkl') \n",
    "\n",
    "# Save the sequence length (important for reconstruction)\n",
    "with open('seq_length.pkl', 'wb') as f:\n",
    "    pickle.dump(seq_length, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f095a70-8d3e-4ac2-9d88-568f0ee9b6bf",
   "metadata": {},
   "source": [
    "### Saving the Last Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c170349-956b-48de-b908-5fd84a735902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the last sequence of scaled data needed for future predictions\n",
    "np.save('last_sequence.npy', scaled_data[-seq_length:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe13734-0859-4089-9f91-ef76585aaa76",
   "metadata": {},
   "source": [
    "### Complete Saving Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ff134b4a-4e5f-4484-9c48-f3516acddb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_forecast_artifacts(model, scaler, scaled_data, seq_length):\n",
    "    # Save model\n",
    "    save_model(model, 'ngn_euro_lstm.h5')\n",
    "    \n",
    "    # Save scaler\n",
    "    joblib.dump(scaler, 'ngn_euro_scaler.pkl')\n",
    "    \n",
    "    # Save sequence length\n",
    "    with open('seq_length.pkl', 'wb') as f:\n",
    "        pickle.dump(seq_length, f)\n",
    "    \n",
    "    # Save last sequence\n",
    "    np.save('last_sequence.npy', scaled_data[-seq_length:])\n",
    "    \n",
    "    print(\"All artifacts saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21436604-a63c-47ad-a123-7203934f241e",
   "metadata": {},
   "source": [
    "##  Create User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70941fa-9088-4137-bd7a-c4de5e973371",
   "metadata": {},
   "source": [
    "### import streamlit as st\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load trained model and scaler\n",
    "model = load_model('ngn_euro_lstm.h5')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "st.title('NGN/EURO Exchange Rate Forecast')\n",
    "\n",
    "# User input for future date\n",
    "future_date = st.date_input(\"Select a future date for prediction:\", \n",
    "                           min_value=datetime.today() + timedelta(days=1))\n",
    "\n",
    "if st.button('Predict'):\n",
    "    # Calculate days ahead\n",
    "    days_ahead = (future_date - datetime.today().date()).days\n",
    "    \n",
    "    # Get last available sequence\n",
    "    last_sequence = scaled_data[-seq_length:]\n",
    "    \n",
    "    # Generate predictions\n",
    "    future_dates = [datetime.today() + timedelta(days=i) for i in range(1, days_ahead+1)]\n",
    "    predictions = forecast_future_dates(model, last_sequence, future_dates, scaler)\n",
    "    \n",
    "    # Get the specific prediction for the selected date\n",
    "    target_prediction = predictions[-1][0]\n",
    "    \n",
    "    st.success(f\"Predicted NGN/EURO rate for {future_date}: {target_prediction:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b011e-d662-4e67-a97b-9850c968bee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
